#!/usr/bin/env python3
"""
SQLiteåˆ«åæ˜ å°„æŸ¥çœ‹å™¨
ç”¨äºæŸ¥çœ‹å’Œåˆ†æexternal_id_mapping.dbä¸­çš„åˆ«åæ˜ å°„æ•°æ®
"""

import sqlite3
import argparse
import sys
from datetime import datetime
from pathlib import Path
from typing import Optional, List, Dict, Tuple
from tabulate import tabulate

# æ”¯æŒçš„å¤–éƒ¨IDç±»å‹
EXTERNAL_ID_TYPES = {
    "DOI", "ArXiv", "CorpusId", "MAG", "ACL", "PMID", "PMCID", "URL", "TITLE_NORM", "DBLP"
}

class SQLiteAliasViewer:
    """SQLiteåˆ«åæ˜ å°„æŸ¥çœ‹å™¨"""
    
    def __init__(self, db_path: str):
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
    
    def _connect(self) -> sqlite3.Connection:
        """è¿æ¥æ•°æ®åº“"""
        return sqlite3.connect(self.db_path)
    
    def show_table_info(self):
        """æ˜¾ç¤ºè¡¨ç»“æ„ä¿¡æ¯"""
        print("\n=== è¡¨ç»“æ„ä¿¡æ¯ ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            # è·å–è¡¨ç»“æ„
            cursor.execute("PRAGMA table_info(external_id_mappings)")
            columns = cursor.fetchall()
            
            if not columns:
                print("âŒ è¡¨ external_id_mappings ä¸å­˜åœ¨")
                return
            
            # æ ¼å¼åŒ–æ˜¾ç¤ºåˆ—ä¿¡æ¯
            headers = ["åˆ—å", "ç±»å‹", "éç©º", "é»˜è®¤å€¼", "ä¸»é”®"]
            table_data = []
            for col in columns:
                table_data.append([
                    col[1],  # name
                    col[2],  # type
                    "æ˜¯" if col[3] else "å¦",  # notnull
                    col[4] or "",  # default_value
                    "æ˜¯" if col[5] else "å¦"   # pk
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            cursor.execute("PRAGMA index_list(external_id_mappings)")
            indexes = cursor.fetchall()
            
            if indexes:
                print("\nğŸ“‹ ç´¢å¼•ä¿¡æ¯:")
                for idx in indexes:
                    print(f"  - {idx[1]} ({'å”¯ä¸€' if idx[2] else 'æ™®é€š'})")
    
    def show_statistics(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯"""
        print("\n=== ç»Ÿè®¡ä¿¡æ¯ ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            # æ€»æ˜ å°„æ•°
            cursor.execute("SELECT COUNT(*) FROM external_id_mappings")
            total_count = cursor.fetchone()[0]
            print(f"ğŸ“Š æ€»æ˜ å°„æ•°: {total_count:,}")
            
            # å”¯ä¸€è®ºæ–‡æ•°
            cursor.execute("SELECT COUNT(DISTINCT paper_id) FROM external_id_mappings")
            unique_papers = cursor.fetchone()[0]
            print(f"ğŸ“„ å”¯ä¸€è®ºæ–‡æ•°: {unique_papers:,}")
            
            # å¹³å‡åˆ«åæ•°
            if unique_papers > 0:
                avg_aliases = total_count / unique_papers
                print(f"ğŸ“ˆ å¹³å‡åˆ«åæ•°: {avg_aliases:.2f}")
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            cursor.execute("""
                SELECT external_type, COUNT(*) 
                FROM external_id_mappings 
                GROUP BY external_type 
                ORDER BY COUNT(*) DESC
            """)
            type_stats = cursor.fetchall()
            
            if type_stats:
                print("\nğŸ“‹ æŒ‰ç±»å‹ç»Ÿè®¡:")
                headers = ["ç±»å‹", "æ•°é‡", "å æ¯”"]
                table_data = []
                for type_name, count in type_stats:
                    percentage = (count / total_count * 100) if total_count > 0 else 0
                    table_data.append([type_name, f"{count:,}", f"{percentage:.1f}%"])
                
                print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def show_recent_mappings(self, limit: int = 10):
        """æ˜¾ç¤ºæœ€è¿‘çš„æ˜ å°„"""
        print(f"\n=== æœ€è¿‘ {limit} æ¡æ˜ å°„ ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT external_type, external_id, paper_id, 
                       datetime(created_at, 'unixepoch') as created,
                       datetime(updated_at, 'unixepoch') as updated
                FROM external_id_mappings 
                ORDER BY updated_at DESC 
                LIMIT ?
            """, (limit,))
            
            results = cursor.fetchall()
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°æ˜ å°„è®°å½•")
                return
            
            headers = ["ç±»å‹", "å¤–éƒ¨ID", "è®ºæ–‡ID", "åˆ›å»ºæ—¶é—´", "æ›´æ–°æ—¶é—´"]
            table_data = []
            for row in results:
                # æˆªæ–­é•¿IDä»¥ä¾¿æ˜¾ç¤º
                external_id = row[1][:50] + "..." if len(row[1]) > 50 else row[1]
                paper_id = row[2][:30] + "..." if len(row[2]) > 30 else row[2]
                
                table_data.append([
                    row[0],  # type
                    external_id,
                    paper_id,
                    row[3] or "æœªçŸ¥",  # created
                    row[4] or "æœªçŸ¥"   # updated
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def show_mappings_by_type(self, external_type: str, limit: int = 20):
        """æŒ‰ç±»å‹æ˜¾ç¤ºæ˜ å°„"""
        print(f"\n=== {external_type} ç±»å‹æ˜ å°„ (å‰ {limit} æ¡) ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT external_id, paper_id, 
                       datetime(created_at, 'unixepoch') as created,
                       datetime(updated_at, 'unixepoch') as updated
                FROM external_id_mappings 
                WHERE external_type = ? 
                ORDER BY updated_at DESC 
                LIMIT ?
            """, (external_type, limit))
            
            results = cursor.fetchall()
            
            if not results:
                print(f"âŒ æ²¡æœ‰æ‰¾åˆ° {external_type} ç±»å‹çš„æ˜ å°„")
                return
            
            headers = ["å¤–éƒ¨ID", "è®ºæ–‡ID", "åˆ›å»ºæ—¶é—´", "æ›´æ–°æ—¶é—´"]
            table_data = []
            for row in results:
                # æˆªæ–­é•¿IDä»¥ä¾¿æ˜¾ç¤º
                external_id = row[0][:60] + "..." if len(row[0]) > 60 else row[0]
                paper_id = row[1][:40] + "..." if len(row[1]) > 40 else row[1]
                
                table_data.append([
                    external_id,
                    paper_id,
                    row[2] or "æœªçŸ¥",
                    row[3] or "æœªçŸ¥"
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def search_mapping(self, search_term: str, search_type: str = "all"):
        """æœç´¢æ˜ å°„"""
        print(f"\n=== æœç´¢ç»“æœ: '{search_term}' ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            if search_type == "external_id":
                query = """
                    SELECT external_type, external_id, paper_id, 
                           datetime(updated_at, 'unixepoch') as updated
                    FROM external_id_mappings 
                    WHERE external_id LIKE ? 
                    ORDER BY updated_at DESC 
                    LIMIT 50
                """
                params = (f"%{search_term}%",)
            elif search_type == "paper_id":
                query = """
                    SELECT external_type, external_id, paper_id, 
                           datetime(updated_at, 'unixepoch') as updated
                    FROM external_id_mappings 
                    WHERE paper_id LIKE ? 
                    ORDER BY updated_at DESC 
                    LIMIT 50
                """
                params = (f"%{search_term}%",)
            else:  # all
                query = """
                    SELECT external_type, external_id, paper_id, 
                           datetime(updated_at, 'unixepoch') as updated
                    FROM external_id_mappings 
                    WHERE external_id LIKE ? OR paper_id LIKE ? 
                    ORDER BY updated_at DESC 
                    LIMIT 50
                """
                params = (f"%{search_term}%", f"%{search_term}%")
            
            cursor.execute(query, params)
            results = cursor.fetchall()
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•")
                return
            
            print(f"âœ… æ‰¾åˆ° {len(results)} æ¡è®°å½•:")
            
            headers = ["ç±»å‹", "å¤–éƒ¨ID", "è®ºæ–‡ID", "æ›´æ–°æ—¶é—´"]
            table_data = []
            for row in results:
                # æˆªæ–­é•¿IDä»¥ä¾¿æ˜¾ç¤º
                external_id = row[1][:50] + "..." if len(row[1]) > 50 else row[1]
                paper_id = row[2][:30] + "..." if len(row[2]) > 30 else row[2]
                
                table_data.append([
                    row[0],  # type
                    external_id,
                    paper_id,
                    row[3] or "æœªçŸ¥"  # updated
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def show_paper_aliases(self, paper_id: str):
        """æ˜¾ç¤ºç‰¹å®šè®ºæ–‡çš„æ‰€æœ‰åˆ«å"""
        print(f"\n=== è®ºæ–‡ {paper_id} çš„æ‰€æœ‰åˆ«å ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT external_type, external_id, 
                       datetime(created_at, 'unixepoch') as created,
                       datetime(updated_at, 'unixepoch') as updated
                FROM external_id_mappings 
                WHERE paper_id = ? 
                ORDER BY external_type, updated_at DESC
            """, (paper_id,))
            
            results = cursor.fetchall()
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°è¯¥è®ºæ–‡çš„åˆ«å")
                return
            
            print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªåˆ«å:")
            
            headers = ["ç±»å‹", "å¤–éƒ¨ID", "åˆ›å»ºæ—¶é—´", "æ›´æ–°æ—¶é—´"]
            table_data = []
            for row in results:
                table_data.append([
                    row[0],  # type
                    row[1],  # external_id (å®Œæ•´æ˜¾ç¤º)
                    row[2] or "æœªçŸ¥",  # created
                    row[3] or "æœªçŸ¥"   # updated
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def show_duplicate_aliases(self):
        """æ˜¾ç¤ºé‡å¤çš„åˆ«åï¼ˆåŒä¸€ä¸ªå¤–éƒ¨IDæ˜ å°„åˆ°å¤šä¸ªè®ºæ–‡ï¼‰"""
        print("\n=== é‡å¤åˆ«åæ£€æŸ¥ ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                SELECT external_type, external_id, COUNT(DISTINCT paper_id) as paper_count,
                       GROUP_CONCAT(DISTINCT paper_id) as paper_ids
                FROM external_id_mappings 
                GROUP BY external_type, external_id 
                HAVING COUNT(DISTINCT paper_id) > 1
                ORDER BY paper_count DESC
            """)
            
            results = cursor.fetchall()
            
            if not results:
                print("âœ… æ²¡æœ‰å‘ç°é‡å¤çš„åˆ«å")
                return
            
            print(f"âš ï¸  å‘ç° {len(results)} ä¸ªé‡å¤åˆ«å:")
            
            headers = ["ç±»å‹", "å¤–éƒ¨ID", "è®ºæ–‡æ•°", "è®ºæ–‡IDs"]
            table_data = []
            for row in results:
                # æˆªæ–­é•¿IDä»¥ä¾¿æ˜¾ç¤º
                external_id = row[1][:40] + "..." if len(row[1]) > 40 else row[1]
                paper_ids = row[3][:80] + "..." if len(row[3]) > 80 else row[3]
                
                table_data.append([
                    row[0],  # type
                    external_id,
                    row[2],  # paper_count
                    paper_ids
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
    
    def delete_paper_mappings(self, paper_id: str, confirm: bool = False):
        """åˆ é™¤ç‰¹å®šè®ºæ–‡çš„æ‰€æœ‰æ˜ å°„"""
        print(f"\n=== åˆ é™¤è®ºæ–‡ {paper_id} çš„æ˜ å°„ ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            # é¦–å…ˆæ£€æŸ¥è¦åˆ é™¤çš„æ˜ å°„
            cursor.execute("""
                SELECT external_type, external_id, 
                       datetime(created_at, 'unixepoch') as created
                FROM external_id_mappings 
                WHERE paper_id = ? 
                ORDER BY external_type, created
            """, (paper_id,))
            
            results = cursor.fetchall()
            
            if not results:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°è¯¥è®ºæ–‡çš„æ˜ å°„ï¼Œæ— éœ€åˆ é™¤")
                return False
            
            print(f"ğŸ“‹ å°†è¦åˆ é™¤ {len(results)} ä¸ªæ˜ å°„:")
            
            headers = ["ç±»å‹", "å¤–éƒ¨ID", "åˆ›å»ºæ—¶é—´"]
            table_data = []
            for row in results:
                table_data.append([
                    row[0],  # type
                    row[1],  # external_id
                    row[2] or "æœªçŸ¥"  # created
                ])
            
            print(tabulate(table_data, headers=headers, tablefmt="grid"))
            
            # ç¡®è®¤åˆ é™¤
            if not confirm:
                print("\nâš ï¸  è¿™æ˜¯ä¸€ä¸ªå±é™©æ“ä½œï¼Œå°†æ°¸ä¹…åˆ é™¤è¿™äº›æ˜ å°„è®°å½•ï¼")
                response = input("ç¡®è®¤åˆ é™¤ï¼Ÿè¯·è¾“å…¥ 'yes' ç»§ç»­: ").strip().lower()
                if response != 'yes':
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    return False
            
            # æ‰§è¡Œåˆ é™¤
            cursor.execute("DELETE FROM external_id_mappings WHERE paper_id = ?", (paper_id,))
            deleted_count = cursor.rowcount
            conn.commit()
            
            print(f"âœ… æˆåŠŸåˆ é™¤ {deleted_count} ä¸ªæ˜ å°„è®°å½•")
            return True
    
    def delete_specific_mapping(self, external_id: str, external_type: str, confirm: bool = False):
        """åˆ é™¤ç‰¹å®šçš„æ˜ å°„è®°å½•"""
        print(f"\n=== åˆ é™¤æ˜ å°„ {external_type}:{external_id} ===")
        
        with self._connect() as conn:
            cursor = conn.cursor()
            
            # é¦–å…ˆæ£€æŸ¥è¦åˆ é™¤çš„æ˜ å°„
            cursor.execute("""
                SELECT paper_id, datetime(created_at, 'unixepoch') as created,
                       datetime(updated_at, 'unixepoch') as updated
                FROM external_id_mappings 
                WHERE external_id = ? AND external_type = ?
            """, (external_id, external_type))
            
            result = cursor.fetchone()
            
            if not result:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°è¯¥æ˜ å°„è®°å½•")
                return False
            
            print("ğŸ“‹ å°†è¦åˆ é™¤çš„æ˜ å°„:")
            print(f"  ç±»å‹: {external_type}")
            print(f"  å¤–éƒ¨ID: {external_id}")
            print(f"  è®ºæ–‡ID: {result[0]}")
            print(f"  åˆ›å»ºæ—¶é—´: {result[1] or 'æœªçŸ¥'}")
            print(f"  æ›´æ–°æ—¶é—´: {result[2] or 'æœªçŸ¥'}")
            
            # ç¡®è®¤åˆ é™¤
            if not confirm:
                print("\nâš ï¸  è¿™æ˜¯ä¸€ä¸ªå±é™©æ“ä½œï¼Œå°†æ°¸ä¹…åˆ é™¤è¿™ä¸ªæ˜ å°„è®°å½•ï¼")
                response = input("ç¡®è®¤åˆ é™¤ï¼Ÿè¯·è¾“å…¥ 'yes' ç»§ç»­: ").strip().lower()
                if response != 'yes':
                    print("âŒ æ“ä½œå·²å–æ¶ˆ")
                    return False
            
            # æ‰§è¡Œåˆ é™¤
            cursor.execute(
                "DELETE FROM external_id_mappings WHERE external_id = ? AND external_type = ?", 
                (external_id, external_type)
            )
            deleted_count = cursor.rowcount
            conn.commit()
            
            print(f"âœ… æˆåŠŸåˆ é™¤æ˜ å°„è®°å½•")
            return True


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="SQLiteåˆ«åæ˜ å°„æŸ¥çœ‹å™¨")
    parser.add_argument(
        "--db", "-d", 
        default="data/external_id_mapping.db",
        help="SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„ (é»˜è®¤: data/external_id_mapping.db)"
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    # infoå‘½ä»¤ - æ˜¾ç¤ºè¡¨ä¿¡æ¯
    subparsers.add_parser("info", help="æ˜¾ç¤ºæ•°æ®åº“è¡¨ç»“æ„ä¿¡æ¯")
    
    # statså‘½ä»¤ - æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    subparsers.add_parser("stats", help="æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯")
    
    # recentå‘½ä»¤ - æ˜¾ç¤ºæœ€è¿‘çš„æ˜ å°„
    recent_parser = subparsers.add_parser("recent", help="æ˜¾ç¤ºæœ€è¿‘çš„æ˜ å°„")
    recent_parser.add_argument("--limit", "-l", type=int, default=10, help="æ˜¾ç¤ºæ¡æ•° (é»˜è®¤: 10)")
    
    # typeå‘½ä»¤ - æŒ‰ç±»å‹æ˜¾ç¤ºæ˜ å°„
    type_parser = subparsers.add_parser("type", help="æŒ‰ç±»å‹æ˜¾ç¤ºæ˜ å°„")
    type_parser.add_argument("external_type", choices=EXTERNAL_ID_TYPES, help="å¤–éƒ¨IDç±»å‹")
    type_parser.add_argument("--limit", "-l", type=int, default=20, help="æ˜¾ç¤ºæ¡æ•° (é»˜è®¤: 20)")
    
    # searchå‘½ä»¤ - æœç´¢æ˜ å°„
    search_parser = subparsers.add_parser("search", help="æœç´¢æ˜ å°„")
    search_parser.add_argument("term", help="æœç´¢å…³é”®è¯")
    search_parser.add_argument(
        "--type", "-t", 
        choices=["all", "external_id", "paper_id"], 
        default="all",
        help="æœç´¢ç±»å‹ (é»˜è®¤: all)"
    )
    
    # paperå‘½ä»¤ - æ˜¾ç¤ºè®ºæ–‡çš„æ‰€æœ‰åˆ«å
    paper_parser = subparsers.add_parser("paper", help="æ˜¾ç¤ºè®ºæ–‡çš„æ‰€æœ‰åˆ«å")
    paper_parser.add_argument("paper_id", help="è®ºæ–‡ID")
    
    # duplicateså‘½ä»¤ - æ˜¾ç¤ºé‡å¤åˆ«å
    subparsers.add_parser("duplicates", help="æ£€æŸ¥é‡å¤åˆ«å")
    
    # delete-paperå‘½ä»¤ - åˆ é™¤è®ºæ–‡çš„æ‰€æœ‰æ˜ å°„
    delete_paper_parser = subparsers.add_parser("delete-paper", help="åˆ é™¤è®ºæ–‡çš„æ‰€æœ‰æ˜ å°„")
    delete_paper_parser.add_argument("paper_id", help="è®ºæ–‡ID")
    delete_paper_parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤ç›´æ¥åˆ é™¤")
    
    # delete-mappingå‘½ä»¤ - åˆ é™¤ç‰¹å®šæ˜ å°„
    delete_mapping_parser = subparsers.add_parser("delete-mapping", help="åˆ é™¤ç‰¹å®šæ˜ å°„")
    delete_mapping_parser.add_argument("external_type", choices=EXTERNAL_ID_TYPES, help="å¤–éƒ¨IDç±»å‹")
    delete_mapping_parser.add_argument("external_id", help="å¤–éƒ¨ID")
    delete_mapping_parser.add_argument("--yes", "-y", action="store_true", help="è·³è¿‡ç¡®è®¤ç›´æ¥åˆ é™¤")
    
    # allå‘½ä»¤ - æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯
    subparsers.add_parser("all", help="æ˜¾ç¤ºæ‰€æœ‰ä¿¡æ¯ (info + stats + recent)")
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        viewer = SQLiteAliasViewer(args.db)
        
        print(f"ğŸ—ƒï¸  æ•°æ®åº“: {args.db}")
        
        if args.command == "info":
            viewer.show_table_info()
        elif args.command == "stats":
            viewer.show_statistics()
        elif args.command == "recent":
            viewer.show_recent_mappings(args.limit)
        elif args.command == "type":
            viewer.show_mappings_by_type(args.external_type, args.limit)
        elif args.command == "search":
            viewer.search_mapping(args.term, args.type)
        elif args.command == "paper":
            viewer.show_paper_aliases(args.paper_id)
        elif args.command == "duplicates":
            viewer.show_duplicate_aliases()
        elif args.command == "delete-paper":
            viewer.delete_paper_mappings(args.paper_id, args.yes)
        elif args.command == "delete-mapping":
            viewer.delete_specific_mapping(args.external_id, args.external_type, args.yes)
        elif args.command == "all":
            viewer.show_table_info()
            viewer.show_statistics()
            viewer.show_recent_mappings(10)
            viewer.show_duplicate_aliases()
        
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æœªçŸ¥é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
